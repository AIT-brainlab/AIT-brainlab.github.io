{{ define "main" }}

<main id="main">
  <!-- ======= Breadcrumbs ======= -->
  <section class="breadcrumbs">
    <div class="container">
      <h2>{{ .Title }}</h2>
    </div>

    </div>
  </section><!-- End Breadcrumbs -->

  <!-- ======= Portfolio Details Section ======= -->
  <section id="portfolio-details" class="portfolio-details">
    <div class="container">
      {{/*  <p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen="" data-align="left" frameborder="0" height="315"
          src="https://www.youtube.com/embed/fMaOqt8tdsg?si=RIPSwUZCM2pqOYw6" style="margin-right:30px;"
          title="YouTube video player" width="500"></iframe>
          <iframe width="500" height="315" src="https://www.youtube.com/embed/2e37nmzC6Ig?si=DOcD4HXIalorkoNK" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          <iframe width="500" height="315" src="https://www.youtube.com/embed/DXnu3WY3znc?si=HWOKOSnhvaP1jAiZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <iframe width="500" height="315" src="https://www.youtube.com/embed/eK-lxMjvbVU?si=jjQM4k9uuF6kY1Wz" title="YouTube video player" frameborder="0" style="margin-left:30px;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </p>
      <!-- <h3><img alt="fun" data-align="left" data-entity-type="file" data-entity-uuid="2205d992-6a3c-48cc-8185-be3c417db181" height="311" src="/sites/default/files/inline-images/IMG20200917192032.jpg" style="margin-right: 20px;" width="500" /></h3> -->  */}}

      <h3>Culture</h3>

      <p>We strive to build an interdisciplinary team working in the area of <strong>natural language processing,
          medical AI </strong>and<strong> brain computer interfaces</strong>. Our core values are:</p>

      <ul>
        <li><strong>Experimental</strong>: We value scientific rigor, focusing on researching under strong scientific
          grounds and conducting sound experiments that provide definitive and repeatable findings.
        </li>
        <li><strong>Computational</strong>: Our scientific nature is to use algorithms, mathematical models, strong
          theoretical background, and strong coding skills.</li>
      </ul>

      <h3>Lab Entry</h3>

      <p>We welcomed students from all disciplines but those with a huge passion for publishing to <b>top-tier
        conferences/journals</b> or <b>making startup-related product</b>. Make sure you read our graduation criteria here first:
        <a href="/researchguide">research guide</a>.  Each year, we TRY not to take more than 10 students a year.
      </p>

      <h3>Current Projects</h3>

      <p>We recommend everyone joining our lab to pursue these continuing projects; we TRY NOT to take any students new
        topics.</p>

      {{/*  <p style="line-height:1.38; margin-top:16px; margin-bottom:16px"><strong>Fundamental Research (suitable for Ph.D. students or Master students who want to go Ph.D.)</strong></p>  */}}

      <ol>
        <li><strong>AI and medical imaging</strong>: Develop models for diagnoses and segmentation through Brain MRI and CT images</li>
        <li><strong>EEG and mental illnesses</strong>: Diagnose mental illnesses / stroke / brain damages using EEG.</li>
        <li><strong>Raman Spectroscopy</strong>: Develop a portable, continuous glucose monitoring system using Raman Spectroscopy</li>
        <li><strong>Multimodal learning and reasoning</strong>: Develop Voice2Text, Sign2Text, Text2Image, Voice2Emotion, VQA models and their applications along with explanations/reasoning</li>
        <li><strong>Compression</strong>: Investigate compression techniques such as pruning, distillation, and quantization </li>
        <li><strong>Reinforcement learning</strong>:  Concerns the use of reinforcement learning, combining with user preferences for the purpose of NLP</li>
        <li><strong>Semi-supervised learning</strong>:  Concerns the use of co-training of labeled and unlabeled data</li>
      </ol>

        {{/*  <li><strong>Knowledge-Based Medical Visual QA</strong>: Just like RAG, we seek to support medical visual QA using some sort of external knowledge systems.</li>
        <li><strong>Multiple-Images Medical Visual QA</strong>:  In the medical scene, especially radiology, it is general that the study is based on multiple images other than a single image. To support that, we need to contribute to model research that support multiple-images medical VQA.</li>
        <li><strong>Stroke and Medical Imaging</strong>: contributes to the early detection of arterial blockage in CT scan images for stroke patients.  Images are provided by Siriraj Hospitals.</li>
        <li><strong>EEG and Mental Health</strong>:  involves measuring stress, mind wandering and mindfulness using EEG, as well as creating interventions such as developing EEG-Based closed-loop neurofeedback applications for attention monitoring and training for young adults</strong></li>
        <li><strong>Glucose monitoring</strong>:contributes to the use of Raman spectroscopy and the development of Raman portables to monitor blood glucose in real-time.</li>
        <li><strong>Sign2Text and Text2Sign</strong>:  contributes to the development of mobile applications that allow deaf people to talk with normal people, e.g., similar to Google Translate.</li>
        <li><strong>Voice emotion</strong>: contributes to the identification of user emotions through voice.  Supports Thai and English.</li>
        <li><strong>Summarization</strong>: summarization is our lab's favorite NLP case study due to its complexity and
          unique challenges. We learned NLP through the lens of summarization by applying different techniques and
          investigates their effectiveness such as:</li>
        <ul>
          <li><strong>Knowledge transfer</strong>: apply knowledge transfer such as shared prefix tuning, multi-task training, self-distillation.</li>
          <li><strong>Masking</strong>: apply selective masking or salient span techniques.</li>
          <li><strong>Progressive pruning and distillation</strong> - apply progressive pruning and distillation.</li>
          <li><strong>Contrastive learning</strong> - apply contrastive
            learning to distinguish between positive and negative topics.</li>
          <li><strong>Reinforcement learning</strong>: apply RL to enforce models to learn through non-differentiable
            metric.</li>
          <li><strong>Mixture of experts</strong>: apply mixture of experts.</li>
        </ul>
      </ol>

      <p><strong>Applied Research (suitable for most Master students and interns)</strong></p>

      <ol>
        <li><strong>BCI speller</strong>:contributes to the development of BCI speller using EEG paradigms such as P300, SSVEP, Hybrid P300-SSVEP and motor imagery for locked-in patients.</li>
        <li><strong>Detecting driver activity and well-being</strong>:  contributes to the detection of driver activity (e.g., distracted) and well-being (e.g., blood pressure) during driving.</li>
        <li><strong>Counting passengers</strong>:  contributes to the accurate counting of passengers.  The challenge is the amount and the possible overlap of passengers coming up.</li>
        <li><strong>Facial Check-in</strong>:  contributes to the development of applications that allow hotels or museums to check-in using only faces.  The challenge is to let customer uploads only one photo and it will work right away.</li>
        <li><strong>AI Thai Government Report</strong>: Thai people often spent hours creating Thai government reports or letters.  Here contributes to the use of AI to help generate commonly used Thai government report that is written in formal government style language.   Style paraphrasing, grammar checkers, and built-in PDF editor are also embedded.</li>
        <li><strong>Scholarly</strong>: contributes to the development of product we called "Scholarly" which help researchers to write papers using style transfer and generative models. Style paraphrasing, grammar checkers, co-writers are among the key modules.</li>
        <li><strong>AI Tourist Guide</strong>: contributes to the development of AI-powered tourist guide.  The idea is to fed a bunch of text that supports multilingual language, and allow an user-specified mascot to speak based on GPS, e.g., talks about some building when the bus arrives that location.
        </li>
        <li><strong>AI Teacher</strong>: contributes to the development of AI-powered teacher.  The idea is to fed a bunch of teaching script that allows the avatar teacher to read the teaching script.  During the class, the system should allow the students to ask questions in real-time (e.g., this can be done via RAG on the teaching script).
        </li>
        <li><strong>AI Sales Assistant</strong>: contributes to the development of an AI-based Sale Assistant which can complement or replace a junior-level sale assistant, including making quotations, answering about products, taking notes, making sales performance report, etc. </li>
        <li><strong>AI Interviewer</strong>: companies get hundreds of applicants.  We seek to develop AI interviewer that can help perform preliminary screening via (1) preliminary chat interviews, and (2) resume scoring.   Through this preliminary screening, huge participants can be screened against job-match criterias.</li>
        <li><strong>ElephantTalking</strong>: contributes to the development of a AI-based call center which involves calling, speech to text, text to text, text to speech, as well as monitoring and notification services to support banking or insurance domain.</li>
      </ol>
      <p></p>  */}}

    </div>
  </section><!-- End Portfolio Details Section -->
</main>
{{ end }}