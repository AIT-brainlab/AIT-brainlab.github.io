{{ define "main" }}

<main id="main">
  <!-- ======= Breadcrumbs ======= -->
  <section class="breadcrumbs">
    <div class="container">
      <h2>{{ .Title }}</h2>
    </div>

    </div>
  </section><!-- End Breadcrumbs -->

  <!-- ======= Portfolio Details Section ======= -->
  <section id="portfolio-details" class="portfolio-details">
    <div class="container">
      <p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen="" data-align="left" frameborder="0" height="315"
          src="https://www.youtube.com/embed/fMaOqt8tdsg?si=RIPSwUZCM2pqOYw6" style="margin-right:30px;"
          title="YouTube video player" width="500"></iframe>
        <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen="" data-align="left" frameborder="0" height="315"
          src="https://www.youtube.com/embed/DXnu3WY3znc?si=lys-pusAv1x6WgRP" style="margin-right:30px;"
          title="YouTube video player" width="500"></iframe>
        <iframe width="500" height="315" src="https://www.youtube.com/embed/x0wkzPLoBjA?si=LNvtDzvoO2rIeLQp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        <iframe width="500" height="315" src="https://www.youtube.com/embed/eK-lxMjvbVU?si=jjQM4k9uuF6kY1Wz" title="YouTube video player" frameborder="0" style="margin-left:30px;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </p>
      <!-- <h3><img alt="fun" data-align="left" data-entity-type="file" data-entity-uuid="2205d992-6a3c-48cc-8185-be3c417db181" height="311" src="/sites/default/files/inline-images/IMG20200917192032.jpg" style="margin-right: 20px;" width="500" /></h3> -->

      <h3>Culture</h3>

      <p>We strive to build an interdisciplinary team working in the area of <strong>natural language processing,
          medical AI </strong>and<strong> brain computer interfaces</strong>. Our core values are:</p>

      <ul>
        <li><strong>Experimental</strong>: We value scientific rigor, focusing on researching under strong scientific
          grounds and conducting sound experiments that provide definitive and repeatable findings.
        </li>
        <li><strong>Computational</strong>: Our scientific nature is to use algorithms, mathematical models, strong
          theoretical background, and strong coding skills.</li>
      </ul>

      <h3>Lab Entry</h3>

      <p>We welcomed students from all disciplines but those with a huge passion for publishing to top-tier
        conferences/journals or making startup-related product. Make sure you read our graduation criteria here first:
        <a href="/researchguide">research guide</a>.  Each year, we TRY not to take more than 10 students a year.
      </p>

      <h3>Internship</h3>

      <p>We welcomed internship students to work on some of the applications/products (not Theory) we are working at.  There is no criteria for finishing internship - the primary function is to give you some real job and let you get it done. Please contact me if you are interested.</p>
      <ul>
        <li>We can provide internship certificate upon your successful completion.</li>
        <li>We currently do not support daily allowances.</li>
        <li>We allow for 2 days remote working and require 3 days full-time in lab.</li>
      </ul>

      <h3>Current Projects</h3>

      <p>We recommend everyone joining our lab to pursue these continuing projects; we TRY NOT to take any students new
        topics.</p>

      <p style="line-height:1.38; margin-top:16px; margin-bottom:16px"><strong>Theory</strong></p>

      <ol>
        <li><strong>Knowledge-Based Medical Visual QA</strong>: Just like RAG, we seek to support medical visual QA using some sort of external knowledge systems.</li>
        <li><strong>Multiple-Images Medical Visual QA</strong>:  In the medical scene, especially radiology, it is general that the study is based on multiple images other than a single image. To support that, we need to contribute to model research that support multiple-images medical VQA.</li>
        <li><strong>Stroke and Medical Imaging</strong>: contributes to the early detection of arterial blockage in CT scan images for stroke patients.  Images are provided by Siriraj Hospitals.</li>
        <li><strong>EEG and Mental Health</strong>:  involves measuring stress, mind wandering and mindfulness using EEG, as well as creating interventions such as developing EEG-Based closed-loop neurofeedback applications for attention monitoring and training for young adults</strong></li>
        <li><strong>Summarization</strong>: summarization is our lab's favorite NLP case study due to its complexity and
          unique challenges. We learned NLP through the lens of summarization by applying different techniques and
          investigates their effectiveness such as:</li>
        <ul>
          <li><strong>Knowledge transfer</strong>: apply knowledge transfer such as shared prefix tuning, multi-task training, self-distillation.</li>
          <li><strong>Masking</strong>: apply selective masking or salient span techniques.</li>
          <li><strong>Progressive pruning and distillation</strong> - apply progressive pruning and distillation.</li>
          <li><strong>Contrastive learning</strong> - apply contrastive
            learning to distinguish between positive and negative topics.</li>
          <li><strong>Reinforcement learning</strong>: apply RL to enforce models to learn through non-differentiable
            metric.</li>
          <li><strong>Mixture of experts</strong>: apply mixture of experts.</li>
        </ul>
      </ol>

      <p><strong>Application</strong></p>

      <ol>
        <li><strong>Glucose monitoring</strong>:contributes to the use of Raman spectroscopy and the development of Raman portables to monitor blood glucose in real-time.</li>
        <li><strong>BCI speller</strong>:contributes to the development of BCI speller using EEG paradigms such as P300, SSVEP, Hybrid P300-SSVEP and motor imagery for locked-in patients.</li>
        <li><strong>AI Thai Government Report</strong>: Thai people often spent hours creating Thai government reports or letters.  Here contributes to the use of AI to help generate commonly used Thai government report that is written in formal government style language.   Style paraphrasing, grammar checkers, and built-in PDF editor are also embedded.</li>
        <li><strong>Scholarly</strong>: contributes to the development of product we called "Scholarly" which help researchers to write papers using style transfer and generative models. Style paraphrasing, grammar checkers, co-writers are among the key modules.</li>
        <li><strong>AI Tourist Guide</strong>: contributes to the development of AI-powered tourist guide.  The idea is to fed a bunch of text that supports multilingual language, and allow an user-specified mascot to speak based on GPS, e.g., talks about some building when the bus arrives that location.
        </li>
        <li><strong>AI Teacher</strong>: contributes to the development of AI-powered teacher.  The idea is to fed a bunch of teaching script that allows the avatar teacher to read the teaching script.  During the class, the system should allow the students to ask questions in real-time (e.g., this can be done via RAG on the teaching script).
        </li>
        <li><strong>AI Sales Assistant</strong>: contributes to the development of an AI-based Sale Assistant which can complement or replace a junior-level sale assistant, including making quotations, answering about products, taking notes, making sales performance report, etc. </li>
        <li><strong>AI Interviewer</strong>: companies get hundreds of applicants.  We seek to develop AI interviewer that can help perform preliminary screening via (1) preliminary chat interviews, and (2) resume scoring.   Through this preliminary screening, huge participants can be screened against job-match criterias.</li>
        <li><strong>ElephantTalking</strong>: contributes to the development of a AI-based call center which involves calling, speech to text, text to text, text to speech, as well as monitoring and notification services to support banking or insurance domain.</li>
      </ol>
      <p></p>

    </div>
  </section><!-- End Portfolio Details Section -->
</main>
{{ end }}