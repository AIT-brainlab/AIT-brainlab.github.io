{{ define "main" }}

<main id="main">
  <!-- ======= Breadcrumbs ======= -->
  <section class="breadcrumbs">
    <div class="container">
      <h2>{{ .Title }}</h2>
    </div>

    </div>
  </section><!-- End Breadcrumbs -->

  <!-- ======= Portfolio Details Section ======= -->
  <section id="portfolio-details" class="portfolio-details">
    <div class="container">
      {{/*  <p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen="" data-align="left" frameborder="0" height="315"
          src="https://www.youtube.com/embed/fMaOqt8tdsg?si=RIPSwUZCM2pqOYw6" style="margin-right:30px;"
          title="YouTube video player" width="500"></iframe>
          <iframe width="500" height="315" src="https://www.youtube.com/embed/2e37nmzC6Ig?si=DOcD4HXIalorkoNK" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          <iframe width="500" height="315" src="https://www.youtube.com/embed/DXnu3WY3znc?si=HWOKOSnhvaP1jAiZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <iframe width="500" height="315" src="https://www.youtube.com/embed/eK-lxMjvbVU?si=jjQM4k9uuF6kY1Wz" title="YouTube video player" frameborder="0" style="margin-left:30px;" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </p>
      <!-- <h3><img alt="fun" data-align="left" data-entity-type="file" data-entity-uuid="2205d992-6a3c-48cc-8185-be3c417db181" height="311" src="/sites/default/files/inline-images/IMG20200917192032.jpg" style="margin-right: 20px;" width="500" /></h3> -->  */}}

      <h3>Culture</h3>

      <p>We strive to build an interdisciplinary team working in the area of <strong>understanding humans</strong> and <strong>improving overall human's wellbeing</strong>.  I called my area of research <b>Human AI Interaction</b>.  It's an interdisciplinary area intersecting technology and humans. Our core values are:</p>

      <ul>
        <li><strong>Experimental</strong>: We value scientific rigor, focusing on researching under strong scientific
          grounds and conducting sound experiments that provide definitive and repeatable findings.
        </li>
        <li><strong>Computational</strong>: Our scientific nature is to use algorithms, mathematical models, strong
          theoretical background, and strong coding skills.</li>
      </ul>

      <h3>Lab Entry</h3>

      <p>We welcomed students from all disciplines but those with a huge passion for research.</p>

      <h3>Current Projects</h3>

      {{/*  <p style="line-height:1.38; margin-top:16px; margin-bottom:16px"><strong>Fundamental Research (suitable for Ph.D. students or Master students who want to go Ph.D.)</strong></p>  */}}
      <p>Understanding humans</p>
      <ol>
        <li><strong>Understanding humans through EEG</strong>: How does EEG profile looks like when humans are stressed?  engaged?  mindful? etc.  Then can we create an intervention system to improve these properties?</li>
        <li><strong>Understanding humans through language</strong>: How can we model beliefs, emotion, cognition, behaviors, cultural/emotional/cognitive biases, etc. in language? </li>
        <li><strong>Understanding humans through voice and face</strong>: Can we detect depression, confidence, humours, or risk profiles from a person's voice?  What should we ask him/her to speak to detect that?  How long should that voice be?  Does it work for only certain languages? Does it get better results if we combine with facial features?</li>
        <li><strong>Understanding humans through learning paradigms</strong>: Can we model human through the lens of multimodal or reinforcement learning? </li>
        <li><strong>Understanding humans through video games + AI</strong>: Can we better understand human through human-game AI interaction to understand their cognitions, emotions, behaviors, social mechanisms? </li>
      </ol>

      <p>Improving humans' well-being and health</p>
      <ol>
        <li><strong>AI for Brain (CT / MRI)</strong>: How to develop an AI system for stroke diagnosis or  hemorrhage?  What are some brain analysis tasks that doctors cannot do very well but AI can?  How to incorporate AI to the current workflow? How to build explaninability and trust? How reasoning can be done and used to improve decision makings?  Can we incorporate VQA?</li>
        <li><strong>AI for Bone Fracture Diagnosis (X-ray)</strong>: How can we develop an AI system for diagnosing bone fractures? What diagnostic tasks related to fractures are challenging for doctors but can be enhanced with AI? How can AI reasoning be integrated to improve decision-making? Can Visual Question Answering (VQA) be incorporated to further assist radiologists?</li>
        <li><strong>Raman Spectroscopy</strong>: How to measure blood glucose non-invasively using Raman spectroscopy?  Can we put them into a portable low-cost machine and deploy them into households?</li>
        <li><strong>EEG BCI Speller</strong>: How to develop an effective and user-friendly BCI speller for locked-in patients using EEG?</li>
        <li><strong>EEG for Meditation</strong>:  It's obvious that meditation has many health benefits. How to integrate EEG to help measure the progress of meditation, as well as a means to help enhance the quality of meditation, e.g., through neurofeedback?</li>
        <li><strong>Chatbot for emotional support</strong>: Can we incorporate CBT/DBT/ACT to chatbot to provide emotional support to people suffering from stress or depression?</li>
        <li><strong>AR / VR / Telepresence robots + chatbot</strong>: How VR/AR or social Telepresence robots can be used to enhance chatbot, e.g., emotional chatbot, personal health assistant?</li>
        <li><strong>Thai Sign2Text</strong>: How to develop a user-friendly mobile-based Sign2Text and Text2Sign application to support communication between deaf people and the society?</li>
        <li><strong>Medical document and image information system</strong>: Hospital has a lot of data but they are mostly disorganized and not properly utilized.  How to develop a system to facilitate medical document processing, e.g., data summarization, data extraction, data annotation, etc.?</li>
      </ol>

      <p>Applications</p>
      <ol>
        <li><strong>AI Multimodal Interviewer</strong>: How AI can be used to help interview applicants for the purpose of recruitment, loan approvals, etc?  How does a complete multimodal solution integrating face, voice, and document processing will look like?</li>
        <li><strong>Emotional-aware, privacy-first sales chatbot</strong>: How to create chatbot that understand what customers' emotions and adapt to their needs?  How to ensure privacy-first conversation through local language models?</li>
        <li><strong>Standing Screen GPT</strong>: How to develop cartonic / real avatar with customized voice and put it on a standing sreen to support sales, tourisms, digital twins, etc.?  What if it even has a webcam and microphone to enable rich interaction between users and the LLM?</li>
        <li><strong>AI Travel Assistant</strong>: What are the current painpoints of traveling / bagpacking?  How AI can be used to reimagine tourism, e.g., planning travels, recommend food, etc.?</li>
        <li><strong>Car damage prediction system</strong>: How to design and develop a system that could accurately and reliably predict car damage?</li>
        <li><strong>AI Marketing</strong>:  How to use AI to design social media ads and use algorithms to finetune the ads for better performance?</li>
      </ol>

    </div>
  </section><!-- End Portfolio Details Section -->
</main>
{{ end }}